This is the code for my final project in CS701 at Middlebury College. I adapted a reference implementation of Transformer (Vaswani et al., 2017) to perform Authorship Attribution. A report containing results from these experiments is available at: http://www.cs.middlebury.edu/~kparikh/files/701-report.pdf.

transformer-aa.py contains all the underlying machinery of the transformer implementation, as well as the script to train and evaluate the model. Parameters are specified as command line arguments when the program is run. This code was adapted from the code provided by Alexander Rush in "The Annotated Transformer." The original code is available at: http://nlp.seas.harvard.edu/2018/04/03/attention.html.




